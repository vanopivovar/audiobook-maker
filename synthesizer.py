"""
–Ø–¥—Ä–æ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ, —ç–∫—Å–ø–æ—Ä—Ç, –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
"""

import os
import re
import time
import wave
import zipfile
import numpy as np
import gradio as gr
from pathlib import Path
from pydub import AudioSegment

from config import SAMPLE_RATE, OUTPUT_DIR, SPEAKERS, FORMATS
from tts_model import model
from text_processing import preprocess_text, split_into_sentences, split_long_sentence
from converters import convert_to_text


def create_detailed_log(
    files: list[dict],
    total_time: float,
    settings: dict
) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –ª–æ–≥-—Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–∏–Ω—Ç–µ–∑–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –ª–æ–≥-—Ñ–∞–π–ª—É.
    """
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    log_filename = f"audiobook_log_{timestamp}.txt"
    log_path = OUTPUT_DIR / log_filename

    # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    total_files = len(files)
    successful_files = sum(1 for f in files if "‚úÖ" in f["–°—Ç–∞—Ç—É—Å"])
    failed_files = sum(1 for f in files if "‚ùå" in f["–°—Ç–∞—Ç—É—Å"])
    total_errors = sum(f.get("–û—à–∏–±–∫–∏", 0) for f in files)

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
    total_size_mb = 0.0
    for f in files:
        if f["–†–∞–∑–º–µ—Ä"] != "-":
            try:
                size_str = f["–†–∞–∑–º–µ—Ä"].replace(" MB", "")
                total_size_mb += float(size_str)
            except (ValueError, AttributeError):
                pass

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ª–æ–≥–∞
    log_content = []
    log_content.append("=" * 70)
    log_content.append("AUDIOBOOK MAKER - –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –û –°–ò–ù–¢–ï–ó–ï")
    log_content.append("=" * 70)
    log_content.append("")

    # –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    log_content.append("üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    log_content.append("-" * 70)
    log_content.append(f"–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    log_content.append(f"–û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time:.2f} —Å–µ–∫ ({total_time/60:.2f} –º–∏–Ω)")
    log_content.append(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_files}")
    log_content.append(f"  ‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful_files}")
    log_content.append(f"  ‚ùå –û—à–∏–±–æ–∫: {failed_files}")
    log_content.append(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_size_mb:.2f} MB")
    log_content.append(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {total_errors}")
    log_content.append("")

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∏–Ω—Ç–µ–∑–∞
    log_content.append("‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò –°–ò–ù–¢–ï–ó–ê")
    log_content.append("-" * 70)
    log_content.append(f"–ì–æ–ª–æ—Å: {settings.get('voice', 'N/A')}")
    log_content.append(f"–°–∫–æ—Ä–æ—Å—Ç—å: {settings.get('speed', 'N/A')}x")
    log_content.append(f"–§–æ—Ä–º–∞—Ç: {settings.get('format', 'N/A')}")
    log_content.append("")

    # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–∞—Ö
    log_content.append("üìÅ –î–ï–¢–ê–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –§–ê–ô–õ–ê–•")
    log_content.append("-" * 70)
    for i, file in enumerate(files, 1):
        log_content.append(f"\n{i}. {file['–§–∞–π–ª']}")
        log_content.append(f"   –°—Ç–∞—Ç—É—Å: {file['–°—Ç–∞—Ç—É—Å']}")
        log_content.append(f"   –ü—Ä–æ–≥—Ä–µ—Å—Å: {file['–ü—Ä–æ–≥—Ä–µ—Å—Å']}")
        log_content.append(f"   –†–∞–∑–º–µ—Ä: {file['–†–∞–∑–º–µ—Ä']}")
        log_content.append(f"   –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {file['–í—Ä–µ–º—è']}")
        log_content.append(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {file['–§—Ä–∞–≥–º–µ–Ω—Ç—ã']}")
        if file.get('–û—à–∏–±–∫–∏', 0) > 0:
            log_content.append(f"   ‚ö†Ô∏è –û—à–∏–±–æ–∫: {file['–û—à–∏–±–∫–∏']}")

    log_content.append("")
    log_content.append("=" * 70)
    log_content.append("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ Audiobook Maker –Ω–∞ –±–∞–∑–µ Silero TTS v5")
    log_content.append("=" * 70)

    # –ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª
    with open(log_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(log_content))

    return str(log_path)


def create_archive_with_files(files: list, log_file: str) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç ZIP-–∞—Ä—Ö–∏–≤ —Å–æ –≤—Å–µ–º–∏ —Ñ–∞–π–ª–∞–º–∏ –∏ –ª–æ–≥–æ–º.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –∞—Ä—Ö–∏–≤—É.
    """
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    archive_name = f"audiobook_bundle_{timestamp}.zip"
    archive_path = OUTPUT_DIR / archive_name

    with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for file_path in files:
            zipf.write(file_path, Path(file_path).name)
        if log_file and Path(log_file).exists():
            zipf.write(log_file, Path(log_file).name)

    return str(archive_path)


def preview_voice(speaker_name: str) -> tuple[str, str]:
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–µ–¥–ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞."""
    try:
        speaker = SPEAKERS.get(speaker_name, "xenia")
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ "–ö—Å–µ–Ω–∏—è (–∂–µ–Ω—Å–∫–∏–π)"
        name = speaker_name.split('(')[0].strip()
        text = f"–ü—Ä–∏–≤–µ—Ç! –Ø {name}."

        audio = model.apply_tts(
            text=text,
            speaker=speaker,
            sample_rate=SAMPLE_RATE,
            put_accent=True,
            put_yo=True,
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        preview_path = OUTPUT_DIR / f"preview_{speaker}.wav"
        audio_int16 = (audio.numpy() * 32767).astype(np.int16)
        segment = AudioSegment(
            audio_int16.tobytes(),
            frame_rate=SAMPLE_RATE,
            sample_width=2,
            channels=1,
        )
        segment.export(str(preview_path), format="wav")

        return str(preview_path), f"‚úÖ {speaker_name}"
    except Exception as e:
        return None, f"‚ùå –û—à–∏–±–∫–∞: {str(e)}"


def synthesize_text(
    text: str,
    speaker_name: str,
    speed: float,
    pause_between_sentences: float,
    output_format: str,
    mp3_tags_title: str,
    mp3_tags_artist: str,
    progress=gr.Progress(track_tqdm=False),
):
    """
    –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ä–µ—á—å –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ—Ç–æ–∫–æ–≤–æ–π –∑–∞–ø–∏—Å—å—é –Ω–∞ –¥–∏—Å–∫.
    –ù–µ –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ –≤ RAM ‚Äî –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (audio_path, download_path, log).
    """

    if not text or not text.strip():
        yield None, None, "‚ùå –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è."
        return

    speaker = SPEAKERS.get(speaker_name, "xenia")
    fmt = FORMATS.get(output_format, FORMATS["MP3 (192 kbps)"])

    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç
    text = preprocess_text(text)
    sentences = split_into_sentences(text)

    if not sentences:
        yield None, None, "‚ùå –¢–µ–∫—Å—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π."
        return

    # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    all_chunks = []
    for s in sentences:
        all_chunks.extend(split_long_sentence(s))

    total = len(all_chunks)
    log_lines = [
        f"üìñ –ù–∞–π–¥–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {total}",
        f"üéô –ì–æ–ª–æ—Å: {speaker_name} ({speaker})",
        f"‚è© –°–∫–æ—Ä–æ—Å—Ç—å: {speed}x",
        f"üíø –§–æ—Ä–º–∞—Ç: {output_format}",
        "",
    ]

    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—É–∑—É –∫–∞–∫ int16 (–æ–¥–∏–Ω —Ä–∞–∑)
    pause_samples = int(SAMPLE_RATE * pause_between_sentences)
    pause_int16 = np.zeros(pause_samples, dtype=np.int16)

    # –í—Ä–µ–º–µ–Ω–Ω—ã–π WAV-—Ñ–∞–π–ª –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –∑–∞–ø–∏—Å–∏
    timestamp = int(time.time())
    safe_title = re.sub(r'[^\w\s-]', '', mp3_tags_title or "audiobook").strip()[:50]
    safe_title = re.sub(r'\s+', '_', safe_title) if safe_title else "audiobook"
    temp_wav_path = OUTPUT_DIR / f"_temp_{safe_title}_{timestamp}.wav"

    start_time = time.time()
    failed_chunks = 0
    written_frames = 0

    # –ü–æ—Ç–æ–∫–æ–≤–∞—è –∑–∞–ø–∏—Å—å: –∫–∞–∂–¥—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å—Ä–∞–∑—É –ø–∏—à–µ—Ç—Å—è –Ω–∞ –¥–∏—Å–∫
    wav_file = wave.open(str(temp_wav_path), 'wb')
    wav_file.setnchannels(1)
    wav_file.setsampwidth(2)  # int16
    wav_file.setframerate(SAMPLE_RATE)

    try:
        for i, chunk in enumerate(all_chunks):
            progress((i + 1) / total, desc=f"–û–∑–≤—É—á–∏–≤–∞–Ω–∏–µ {i+1}/{total}...")

            try:
                audio = model.apply_tts(
                    text=chunk,
                    speaker=speaker,
                    sample_rate=SAMPLE_RATE,
                    put_accent=True,
                    put_yo=True,
                    put_stress_homo=True,
                    put_yo_homo=True,
                )
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ä–∞–∑—É –Ω–∞ –¥–∏—Å–∫
                audio_int16 = (audio.numpy() * 32767).astype(np.int16)
                wav_file.writeframes(audio_int16.tobytes())
                wav_file.writeframes(pause_int16.tobytes())
                written_frames += len(audio_int16) + pause_samples
            except Exception as e:
                failed_chunks += 1
                log_lines.append(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ {i+1}/{total}: {str(e)[:100]}")
                log_lines.append(f"   –¢–µ–∫—Å—Ç: {chunk[:80]}...")

                if failed_chunks > total * 0.3:
                    wav_file.close()
                    temp_wav_path.unlink(missing_ok=True)
                    error_msg = (
                        f"\n\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ ({failed_chunks}/{total})\n"
                        f"–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\n"
                        f"‚Ä¢ –¢–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã\n"
                        f"‚Ä¢ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏\n\n"
                        f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
                        f"‚Ä¢ –†–∞–∑–¥–µ–ª–∏—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏\n"
                        f"‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ñ–∞–π–ª–∞"
                    )
                    yield None, None, "\n".join(log_lines) + error_msg
                    return
                continue
    finally:
        wav_file.close()

    if written_frames == 0:
        temp_wav_path.unlink(missing_ok=True)
        yield None, None, "\n".join(log_lines) + "\n\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞."
        return

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª
    filename = f"{safe_title}_{speaker}_{timestamp}{fmt['ext']}"
    output_path = OUTPUT_DIR / filename

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏/–∏–ª–∏ —Ñ–æ—Ä–º–∞—Ç–∞
    # pydub –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å –¥–∏—Å–∫–∞, –Ω–µ –∏–∑ RAM —Ü–µ–ª–∏–∫–æ–º
    segment = AudioSegment.from_wav(str(temp_wav_path))

    if speed != 1.0:
        new_frame_rate = int(SAMPLE_RATE * speed)
        segment = segment._spawn(
            segment.raw_data,
            overrides={"frame_rate": new_frame_rate},
        )
        segment = segment.set_frame_rate(SAMPLE_RATE)

    # –≠–∫—Å–ø–æ—Ä—Ç —Å —Ç–µ–≥–∞–º–∏
    export_params = dict(fmt["params"])
    tags = {}
    if mp3_tags_title:
        tags["title"] = mp3_tags_title
        tags["album"] = mp3_tags_title
    if mp3_tags_artist:
        tags["artist"] = mp3_tags_artist
    if tags:
        export_params["tags"] = tags

    segment.export(str(output_path), format=fmt["format"], **export_params)

    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π WAV
    duration_sec = len(segment) / 1000
    del segment
    temp_wav_path.unlink(missing_ok=True)

    elapsed = time.time() - start_time
    file_size_mb = output_path.stat().st_size / (1024 * 1024)

    log_lines.extend([
        f"‚úÖ –ì–æ—Ç–æ–≤–æ –∑–∞ {elapsed:.1f} —Å–µ–∫",
        f"üïê –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration_sec:.1f} —Å–µ–∫ ({duration_sec/60:.1f} –º–∏–Ω)",
        f"üìÅ –†–∞–∑–º–µ—Ä: {file_size_mb:.1f} MB",
        f"üíæ –§–∞–π–ª: {filename}",
    ])

    yield str(output_path), str(output_path), "\n".join(log_lines)


def synthesize_file(
    file,
    speaker_name: str,
    speed: float,
    pause_between_sentences: float,
    output_format: str,
    mp3_tags_title: str,
    mp3_tags_artist: str,
    progress=gr.Progress(track_tqdm=False),
):
    """–°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ä–µ—á—å –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."""
    if file is None:
        yield None, None, "‚ùå –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª."
        return

    file_path = file if isinstance(file, str) else file.name

    # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ –º–æ–¥—É–ª—å converters
    text, debug_info = convert_to_text(file_path)

    if text is None:
        error_msg = f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞.\n\nüîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:\n{debug_info}"
        yield None, None, error_msg
        return

    if not text.strip():
        yield None, None, "‚ùå –§–∞–π–ª –ø—É—Å—Ç."
        return

    # –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –±–µ—Ä—ë–º –∏–º—è —Ñ–∞–π–ª–∞
    if not mp3_tags_title:
        mp3_tags_title = Path(file_path).stem

    yield from synthesize_text(
        text, speaker_name, speed, pause_between_sentences,
        output_format, mp3_tags_title, mp3_tags_artist, progress,
    )
